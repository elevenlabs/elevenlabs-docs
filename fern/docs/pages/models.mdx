---
title: Models
description: Learn about the models that power the ElevenLabs API.
---

## Flagship models

<Markdown src="/snippets/tts-models.mdx" />
<Markdown src="/snippets/stt-models.mdx" />
<div className="text-center">
  <div>[Pricing](https://elevenlabs.io/pricing/api)</div>
</div>

## Models overview

The ElevenLabs API offers a range of audio models optimized for different use cases, quality levels, and performance requirements.

| Model ID                     | Description                                                                                                                                                                                                           | Languages                                                                                                                                                                     |
| ---------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `eleven_multilingual_v2`     | Our most lifelike model with rich emotional expression                                                                                                                                                                | `en`, `ja`, `zh`, `de`, `hi`, `fr`, `ko`, `pt`, `it`, `es`, `id`, `nl`, `tr`, `fil`, `pl`, `sv`, `bg`, `ro`, `ar`, `cs`, `el`, `fi`, `hr`, `ms`, `sk`, `da`, `ta`, `uk`, `ru` |
| `eleven_flash_v2_5`          | Ultra-fast model optimized for real-time use (~75ms&dagger;)                                                                                                                                                          | All `eleven_multilingual_v2` languages plus: `hu`, `no`, `vi`                                                                                                                 |
| `eleven_flash_v2`            | Ultra-fast model optimized for real-time use (~75ms&dagger;)                                                                                                                                                          | `en`                                                                                                                                                                          |
| `eleven_multilingual_sts_v2` | State-of-the-art multilingual voice changer model (Speech to Speech)                                                                                                                                                  | `en`, `ja`, `zh`, `de`, `hi`, `fr`, `ko`, `pt`, `it`, `es`, `id`, `nl`, `tr`, `fil`, `pl`, `sv`, `bg`, `ro`, `ar`, `cs`, `el`, `fi`, `hr`, `ms`, `sk`, `da`, `ta`, `uk`, `ru` |
| `eleven_english_sts_v2`      | English-only voice changer model (Speech to Speech)                                                                                                                                                                   | `en`                                                                                                                                                                          |
| `scribe_v1`                  | State-of-the-art speech recognition model                                                                                                                                                                             | [99 languages](/docs/capabilities/speech-to-text#supported-languages)                                                                                                         |
| `scribe_v1_experimental`     | State-of-the-art speech recognition model with experimental features: improved multilingual performance, reduced hallucinations during silence, fewer audio tags, and better handling of early transcript termination | [99 languages](/docs/capabilities/speech-to-text#supported-languages)                                                                                                         |

<small>† Excluding application & network latency</small>

<Accordion title="Older Models">

<Warning>

These models are maintained for backward compatibility but are not recommended for new projects.

</Warning>

| Model ID                 | Description                                                                 | Languages                                                                                                                                                                                       |
| ------------------------ | --------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `eleven_monolingual_v1`  | First generation TTS model (outclassed by v2 models)                        | `en`                                                                                                                                                                                            |
| `eleven_multilingual_v1` | First multilingual model (outclassed by v2 models)                          | `en`, `fr`, `de`, `hi`, `it`, `pl`, `pt`, `es`                                                                                                                                                  |
| `eleven_turbo_v2_5`      | High quality, low-latency model (~250ms-300ms) (outclassed by Flash models) | `en`, `ja`, `zh`, `de`, `hi`, `fr`, `ko`, `pt`, `it`, `es`, `id`, `nl`, `tr`, `fil`, `pl`, `sv`, `bg`, `ro`, `ar`, `cs`, `el`, `fi`, `hr`, `ms`, `sk`, `da`, `ta`, `uk`, `ru`, `hu`, `no`, `vi` |
| `eleven_turbo_v2`        | High quality, low-latency model (~250ms-300ms) (outclassed by Flash models) | `en`                                                                                                                                                                                            |

</Accordion>

## Multilingual v2

Eleven Multilingual v2 is our most advanced, emotionally-aware speech synthesis model. It produces natural, lifelike speech with high emotional range and contextual understanding across multiple languages.

The model delivers consistent voice quality and personality across all supported languages while maintaining the speaker's unique characteristics and accent.

This model excels in scenarios requiring high-quality, emotionally nuanced speech:

- **Audiobook Production**: Perfect for long-form narration with complex emotional delivery
- **Character Voiceovers**: Ideal for gaming and animation due to its emotional range
- **Professional Content**: Well-suited for corporate videos and e-learning materials
- **Multilingual Projects**: Maintains consistent voice quality across language switches

While it has a higher latency & cost per character than Flash models, it delivers superior quality for projects where lifelike speech is important.

<Markdown src="/snippets/v2-model-languages.mdx" />

## Flash v2.5

Eleven Flash v2.5 is our fastest speech synthesis model, designed for real-time applications and conversational AI. It delivers high-quality speech with ultra-low latency (~75ms&dagger;) across 32 languages.

The model balances speed and quality, making it ideal for interactive applications while maintaining natural-sounding output and consistent voice characteristics across languages.

This model is particularly well-suited for:

- **Conversational AI**: Perfect for real-time voice agents and chatbots
- **Interactive Applications**: Ideal for games and applications requiring immediate response
- **Large-Scale Processing**: Efficient for bulk text-to-speech conversion

With its lower price point and 75ms latency, Flash v2.5 is the cost-effective option for anyone needing fast, reliable speech synthesis across multiple languages.

<Markdown src="/snippets/v2-5-model-languages.mdx" />

### Considerations

<AccordionGroup>
  <Accordion title="Text normalization with numbers">
    When using Flash v2.5, numbers aren't normalized in a way you might expect. For example, phone numbers might be read out in way that isn't clear for the user. Dates and currencies are affected in a similar manner.

    This is expected as normalization is disabled for Flash v2.5 to maintain the low latency.

    The Multilingual v2 model does a better job of normalizing numbers, so we recommend using it for phone numbers and other cases where number normalization is important.

    For low-latency or Conversational AI applications, best practice is to have your LLM [normalize the text](/docs/best-practices/prompting/normalization) before passing it to the TTS model.

  </Accordion>
</AccordionGroup>

## Model selection guide

<AccordionGroup>
  <Accordion title="Requirements">
    <CardGroup cols={1}>
      <Card title="Quality">
        Use `eleven_multilingual_v2`

        Best for high-fidelity audio output with rich emotional expression
      </Card>
      <Card title="Low-latency">
        Use Flash models

        Optimized for real-time applications (~75ms latency)
      </Card>
      <Card title="Multilingual">
        Use either either `eleven_multilingual_v2` or `eleven_flash_v2_5`

        Both support up to 32 languages
      </Card>
    </CardGroup>

  </Accordion>

  <Accordion title="Use case">
    <CardGroup cols={1}>
      <Card title="Content creation">
        Use `eleven_multilingual_v2`

        Ideal for professional content, audiobooks & video narration.
      </Card>

      <Card title="Conversational AI">
        Use `eleven_flash_v2_5`, `eleven_flash_v2` or `eleven_multilingual_v2`

        Perfect for real-time conversational applications
      </Card>

      <Card title="Voice changer">
        Use `eleven_multilingual_sts_v2`

        Specialized for Speech-to-Speech conversion
      </Card>
    </CardGroup>

  </Accordion>
</AccordionGroup>

## Character limits

The maximum number of characters supported in a single text-to-speech request varies by model.

| Model ID                 | Character limit | Approximate audio duration |
| ------------------------ | --------------- | -------------------------- |
| `eleven_flash_v2_5`      | 40,000          | ~40 minutes                |
| `eleven_flash_v2`        | 30,000          | ~30 minutes                |
| `eleven_multilingual_v2` | 10,000          | ~10 minutes                |
| `eleven_multilingual_v1` | 10,000          | ~10 minutes                |
| `eleven_english_sts_v2`  | 10,000          | ~10 minutes                |
| `eleven_english_sts_v1`  | 10,000          | ~10 minutes                |

<Note>For longer content, consider splitting the input into multiple requests.</Note>

## Scribe v1

Scribe v1 is our state-of-the-art speech recognition model designed for accurate transcription across 99 languages. It provides precise word-level timestamps and advanced features like speaker diarization and dynamic audio tagging.

This model excels in scenarios requiring accurate speech-to-text conversion:

- **Transcription Services**: Perfect for converting audio/video content to text
- **Meeting Documentation**: Ideal for capturing and documenting conversations
- **Content Analysis**: Well-suited for audio content processing and analysis
- **Multilingual Recognition**: Supports accurate transcription across 99 languages

Key features:

- Accurate transcription with word-level timestamps
- Speaker diarization for multi-speaker audio
- Dynamic audio tagging for enhanced context
- Support for 99 languages

Read more about Scribe v1 [here](/docs/capabilities/speech-to-text).

## Concurrency and priority

Your subscription plan determines how many requests can be processed simultaneously and the priority level of your requests in the queue.
Speech to Text has an elevated concurrency limit.
Once the concurrency limit is met, subsequent requests are processed in a queue alongside lower-priority requests.
In practice this typically only adds ~50ms of latency.

| Plan       | Concurrency Limit | STT Concurrency Limit | Priority level |
| ---------- | ----------------- | --------------------- | -------------- |
| Free       | 4                 | 10                    | 3              |
| Starter    | 6                 | 15                    | 4              |
| Creator    | 10                | 25                    | 5              |
| Pro        | 20                | 50                    | 5              |
| Scale      | 30                | 75                    | 5              |
| Business   | 30                | 75                    | 5              |
| Enterprise | Elevated          | Elevated              | Highest        |

<Note>
  To increase your concurrency limit & queue priority, [upgrade your subscription
  plan](https://elevenlabs.io/pricing/api).

Enterprise customers can request a higher concurrency limit by contacting their account manager.

</Note>

The response headers include `current-concurrent-requests` and `maximum-concurrent-requests` which you can use to monitor your concurrency.

### Concurrency limits - best practises

As a general rule of thumb, a concurrency limit of **5 can approximately support up to 100 simultaneous TTS requests**.

However, this depends on several factors, including the selected model, the specific AI voices used, and the nature of the use case. For instance, Turbo models may support more concurrent requests than this baseline suggests.

For character voiceovers, where TTS is used to facilitate dialogue, concurrency requirements can vary. Factors such as a character’s dialogue frequency, the length of pauses, and in-game actions between lines can all influence the necessary concurrency limit. In general, these use cases may support more requests than what the provided heuristic suggests.

For live dubbing use cases—especially those involving multiple speakers in a conversational or narrative context—concurrency demands also tend to remain within the base estimate. Since multiple voices are often processed sequentially, a higher number of requests can typically be supported.

For conversational AI use cases, concurrency requirements depend on the speaking ratio between the AI agent and the human participant. For example, in customer support scenarios where the AI agent speaks less frequently than the user, a concurrency limit of 5 may support more than 100 simultaneous requests.
