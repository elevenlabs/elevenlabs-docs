---
title: Language
subtitle: Learn how to configure your agent to speak multiple languages.
---

## Overview

This guide shows you how to configure your agent to speak multiple languages. You'll learn to:

- Configure your agent's primary language
- Add support for multiple languages
- Set language-specific voices and first messages
- Optimize voice selection for natural pronunciation

## Guide

<Steps>

<Step title="Default agent language">
When you create a new agent, it's configured with:

- English as the primary language
- Flash v2 model for fast, English-only responses
- A default first message.

<Frame background="subtle">
  <img
    height="400px"
    alt="Conversational AI language overview"
    src="/assets/images/conversational-ai-language-overview.png"
  />
</Frame>

<Note>
  Adding any additional language automatically upgrades the agent to use our
  v2.5 Multilingual model.
</Note>

</Step>

<Step title="Add additional languages">
First, navigate to your agent's configuration page and locate the **Agent** tab.

1. In the **Additional Languages** add an additional language (e.g. French)
2. Review the automatically translated first message, and if needed, customize it for each additional language.

<Frame background="subtle">
  <img
    height="450px"
    alt="Conversational AI language selection"
    src="/assets/images/conversational-ai-language-selection.png"
  />
</Frame>

<Note>
  Selecting the **All** option in the **Additional Languages** dropdown will
  configure the agent to support 32 languages. Collectively, these languages are
  spoken by approximately 90% of the world's population.
</Note>

</Step>

<Step title="Configure language-specific voices">
For optimal pronounciation, configure each additional language with a language-specific voice from our [Voice Library](https://elevenlabs.io/app/voice-library).

<Tabs>
<Tab title="Language-specific voice settings">
<Frame background="subtle">
  <img
    height="270px"
    alt="Conversational AI language-specific voice setting"
    src="/assets/images/conversational-ai-language-voice.png"
  />
</Frame>
</Tab>
<Tab title="Voice library">
<Frame background="subtle">
  <img
    height="160px"
    alt="Conversational AI voice library language"
    src="/assets/images/conversational-ai-voice-library-language.png"
  />
</Frame>
</Tab>

</Tabs>
</Step>

<Step title="Starting a call">

Now that the agent is configured to support additional languages, the widget will prompt the user for their preferred language before the conversation begins.

If using the SDK, the language can be set programmatically using conversation overrides. See the
[Dynamic Conversation](/docs/conversational-ai/customization/conversation-configuration) guide for implementation details.

<Frame background="subtle">
  <img
    height="400px"
    alt="Language selection before call"
    src="/assets/images/conversational-ai-call-voice-selection.png"
  />
</Frame>

<Note>
  Language selection is fixed for the duration of the call - users cannot switch
  languages mid-conversation.
</Note>

</Step>

</Steps>

## Best practices

<AccordionGroup>
<Accordion title="Voice selection">
  Select voices specifically trained in your target languages. This ensures:
  - Natural pronunciation
  - Appropriate regional accents
  - Better handling of language-specific nuances
</Accordion>

<Accordion title="First message customization">
While automatic translations are provided, consider:

<div>
  
 - Reviewing translations for accuracy 
 - Adapting greetings for cultural context 
 - Adjusting formal/informal tone as needed

</div>
</Accordion>
</AccordionGroup>
