---
title: WebSocket
subtitle: Create real-time, interactive voice conversations with AI agents
slug: conversational-ai/api-reference/websocket
---


<Note>
  This documentation is for developers integrating directly with the ElevenLabs
  WebSocket API. For convenience, consider using [the official SDKs provided by
  ElevenLabs](/docs/conversational-ai/docs/introduction).
</Note>

The ElevenLabs [Conversational AI](https://elevenlabs.io/conversational-ai) WebSocket API enables real-time, interactive voice conversations with AI agents. By establishing a WebSocket connection, you can send audio input and receive audio responses in real-time, creating life-like conversational experiences.

<Note>
  Endpoint: `wss://api.elevenlabs.io/v1/convai/conversation?agent_id={agent_id}`
</Note>

## Authentication

### Using Agent ID

For public agents, you can directly use the `agent_id` in the WebSocket URL without additional authentication:

```bash
wss://api.elevenlabs.io/v1/convai/conversation?agent_id=<your-agent-id>
```

### Using a Signed URL

For private agents or conversations requiring authorization, obtain a signed URL from your server, which securely communicates with the ElevenLabs API using your API key.

### Example using cURL

**Request:**

```bash
curl -X GET "https://api.elevenlabs.io/v1/convai/conversation/get_signed_url?agent_id=<your-agent-id>" \
     -H "xi-api-key: <your-api-key>"
```

**Response:**

```json
{
  "signed_url": "wss://api.elevenlabs.io/v1/convai/conversation?agent_id=<your-agent-id>&token=<token>"
}
```

<Warning>Never expose your ElevenLabs API key on the client side.</Warning>

## Communication

### Client-to-Server Messages

#### User Audio Chunk

Send audio data from the user to the server.

**Format:**

```json
{
  "user_audio_chunk": "<base64-encoded-audio-data>"
}
```

**Notes:**

- **Audio Format Requirements:**

  - PCM 16-bit mono format
  - Base64 encoded
  - Sample rate of 16,000 Hz

- **Recommended Chunk Duration:**

  - Send audio chunks approximately every **250 milliseconds (0.25 seconds)**
  - This equates to chunks of about **4,000 samples** at a 16,000 Hz sample rate

- **Optimizing Latency and Efficiency:**
  - **Balance Latency and Efficiency:** Sending audio chunks every 250 milliseconds offers a good trade-off between responsiveness and network overhead.
  - **Adjust Based on Needs:**
    - _Lower Latency Requirements:_ Decrease the chunk duration to send smaller chunks more frequently.
    - _Higher Efficiency Requirements:_ Increase the chunk duration to send larger chunks less frequently.
  - **Network Conditions:** Adapt the chunk size if you experience network constraints or variability.

#### Pong Message

Respond to server `ping` messages by sending a `pong` message, ensuring the `event_id` matches the one received in the `ping` message.

**Format:**

```json
{
  "type": "pong",
  "event_id": 12345
}
```

### Server-to-Client Messages

#### conversation_initiation_metadata

Provides initial metadata about the conversation.

**Format:**

```json
{
  "type": "conversation_initiation_metadata",
  "conversation_initiation_metadata_event": {
    "conversation_id": "conv_123456789",
    "agent_output_audio_format": "pcm_16000"
  }
}
```

### Other Server-to-Client Messages

| Type               | Purpose                                             |
| ------------------ | --------------------------------------------------- |
| user_transcript    | Transcriptions of the user's speech                 |
| agent_response     | Agent's textual response                            |
| audio              | Chunks of the agent's audio response                |
| interruption       | Indicates that the agent's response was interrupted |
| ping               | Server pings to measure latency                     |
| client-tool-call   | Initiate client tool call                           |
| client-tool-result | Response for the client tool call                   |

##### Message Formats

**user_transcript:**

```json
{
  "type": "user_transcript",
  "user_transcription_event": {
    "user_transcript": "Hello, how are you today?"
  }
}
```

**agent_response:**

```json
{
  "type": "agent_response",
  "agent_response_event": {
    "agent_response": "Hello! I'm doing well, thank you for asking. How can I assist you today?"
  }
}
```

**audio:**

```json
{
  "type": "audio",
  "audio_event": {
    "audio_base_64": "SGVsbG8sIHRoaXMgaXMgYSBzYW1wbGUgYXVkaW8gY2h1bms=",
    "event_id": 67890
  }
}
```

**interruption:**

```json
{
  "type": "interruption",
  "interruption_event": {
    "event_id": 54321
  }
}
```

**internal_tentative_agent_response:**

```json
{
  "type": "internal_tentative_agent_response",
  "tentative_agent_response_internal_event": {
    "tentative_agent_response": "I'm thinking about how to respond..."
  }
}
```

**ping:**

```json
{
  "type": "ping",
  "ping_event": {
    "event_id": 13579,
    "ping_ms": 50
  }
}
```

**client_tool_call:**

```json
{
  "type": "client_tool_call",
  "client_tool_call": {
    "tool_name": string,
    "tool_call_id": string,
    "parameters": dict,
  }
}
```

**client_tool_result:**

```json
{
  "type": "client_tool_result",
  "tool_call_id": str,
  "result": str,
  "is_error": bool,
}
```

## Latency Management

To ensure smooth conversations, implement these strategies:

- **Adaptive Buffering:** Adjust audio buffering based on network conditions.
- **Jitter Buffer:** Implement a jitter buffer to smooth out variations in packet arrival times.
- **Ping-Pong Monitoring:** Use ping and pong events to measure round-trip time and adjust accordingly.

## Security Best Practices

- Rotate API keys regularly and use environment variables to store them.
- Implement rate limiting to prevent abuse.
- Clearly explain the intention when prompting users for microphone access.
- Optimized Chunking: Tweak the audio chunk duration to balance latency and efficiency.

## Additional Resources

- [ElevenLabs Conversational AI Documentation](https://elevenlabs.io/docs/conversational-ai/overview)
- [ElevenLabs Conversational AI SDKs](https://elevenlabs.io/docs/conversational-ai/client-sdk)
