---
title: HIPAA compliance
subtitle: Learn how ElevenLabs Conversational AI supports HIPAA compliance for healthcare applications
---

<Warning>
  This guide is a technical overview of our HIPAA compliance. Please refer to our [compliance
  page](https://compliance.elevenlabs.io/) for the latest information.
</Warning>

## Overview

ElevenLabs Conversational AI is part of the eligible services we can sign a Business Associate Agreement for that is in line with HIPAA compliance, allowing healthcare organizations to build voice agents that handle protected health information (PHI) while maintaining regulatory compliance. This feature ensures that sensitive patient data is properly protected throughout the conversation lifecycle.

## How HIPAA compliance works

When HIPAA compliance is enabled for a workspace, the following policies are enabled:

1. **Zero Data Retention (ZDR)** - All sensitive data from conversations is automatically redacted before storage. This also applies to derivative data like LLM-produced transcript summaries, and tool call parameters and results.
2. **LLM Provider Restrictions** - Only LLMs from providers that ElevenLabs has signed a Business Associate Agreement (BAA) with are available as preconfigured options to ensure compliance
3. **Storage Limitations** - Raw audio files and transcripts containing PHI are not retained

<Note>

If you want to use LLMs that aren't available preconfigured in ZDR mode (e.g., OpenAI's GPT-4o mini), you
can still use them in Conversational AI by:

1. Arranging to sign a BAA directly with the LLM provider you'd like to use
2. Using your API key with our Custom LLM integration

</Note>

ElevenLabs' platform ensures that PHI shared as part of a conversation is not inadvertently stored or logged in any system component, including:

- Conversation transcripts
- Audio recordings
- Tool calls and results
- Data analytics
- System logs

<Warning>
  With Conversational AI, the BAA covers conversation content only - agent configuration is
  persisted and so is not covered by Zero Retention Mode and should not include PHI. Therefore,
  documents uploaded by an agent owner to the [Knowledge
  base](/docs/conversational-ai/customization/knowledge-base) aren't covered and should not include
  PHI.
</Warning>

### Enabling HIPAA compliance

<Note>
  HIPAA compliance is only available on Enterprise tier subscriptions and requires a BAA to be in
  place between you and ElevenLabs. Contact your account representative to discuss enabling this
  feature for your organization.
</Note>

## HIPAA-Compliant LLMs

When operating in HIPAA mode, only the following LLMs are available:

<AccordionGroup>

  <Accordion title="Google Models">
    - Gemini 2.0 Flash 
    - Gemini 2.0 Flash Lite 
    - Gemini 1.5 Flash 
    - Gemini 1.5 Pro 
    - Gemini 1.0 Pro
  </Accordion>
  <Accordion title="Anthropic Models">
    - Claude 3.7 Sonnet 
    - Claude 3.5 Sonnet 
    - Claude 3.0 Haiku
  </Accordion>
  <Accordion title="Custom LLMs">
    - [Custom LLM](/docs/conversational-ai/customization/custom-llm) (supports any OpenAI-API compatible provider, requires you to bring your own API keys)
  </Accordion>
  
</AccordionGroup>

## Technical implementation

The HIPAA compliance feature implements several safeguards including but not limited to:

1. **LLM Allowlist** - Prevents use of non-compliant LLMs
2. **PII Redaction** - Automatically redacts sensitive fields before storage
3. **Storage Prevention** - Disables uploading of raw audio files to cloud

## Developer experience

When working with HIPAA-compliant agents:

<Steps>
  <Step title="Non-compliant LLMs are disabled in the UI">
    <Frame
      background="subtle"
      caption="The UI shows disabled LLM options with tooltip explanations"
    >
      ![Redacted conversation analysis showing HIPAA compliance in
      action](/assets/images/conversational-ai/hipaa-model.png)
    </Frame>
  </Step>
  <Step title="Content is redacted from content history">
    <Frame background="subtle" caption="All sensitive information is redacted and not stored">
      ![Redacted conversation history showing HIPAA compliance in
      action](/assets/images/conversational-ai/redacted.png)
    </Frame>
  </Step>
  <Step title="Conversation analysis is limited">
    <Frame
      background="subtle"
      caption="Analysis and summaries maintain HIPAA compliance through redaction"
    >
      ![Redacted conversation analysis showing HIPAA compliance in
      action](/assets/images/conversational-ai/redacted-summary.png)
    </Frame>
  </Step>
</Steps>

### API restrictions are enforced

API calls attempting to use non-compliant LLMs will receive an HTTP 400 error. Analytics data will be limited to non-sensitive metrics only.

## FAQ

<AccordionGroup>
  <Accordion title="Can I use any LLM with HIPAA compliance enabled?">
    No. When HIPAA compliance is enabled, you can only use LLMs from the approved list. Attempts to
    use non-compliant LLMs will produce an error. You can always use a custom LLM if you need a
    specific model not on the allowlist.
  </Accordion>
  <Accordion title="How do I know if my workspace has HIPAA compliance enabled?">
    HIPAA compliance is only available to enterprise customers. Please refer to your account
    executive to check if this is enabled.
  </Accordion>
  <Accordion title="Does HIPAA compliance affect conversation quality?">
    No. HIPAA compliance only affects how data is stored and which LLMs can be used. It does not
    impact the quality or functionality of conversations while they are active.
  </Accordion>
  <Accordion title="Can I still analyze conversation data with HIPAA enabled?">
    Yes, but with limitations. Conversation analytics will only include non-sensitive metadata like
    call duration and success rates. Specific content from conversations will be redacted.
  </Accordion>
</AccordionGroup>

## Best practices

When building HIPAA-compliant voice agents:

1. **Use Custom LLMs** when possible for maximum control over data processing
2. **Implement proper authentication** for all healthcare applications
3. **Validate configuration** is correct by checking redaction before launching + passing PHI

## Related resources

<CardGroup cols={2}>
  <Card
    title="Conversational AI Security"
    href="/docs/conversational-ai/customization/authentication"
  >
    Learn about securing your Conversational AI agents
  </Card>
  <Card title="Custom LLM Integration" href="/docs/conversational-ai/customization/custom-llm">
    Set up your own LLM for maximum control and compliance
  </Card>
</CardGroup>
