---
title: HIPAA compliance
subtitle: Learn how ElevenLabs Conversational AI supports HIPAA compliance for healthcare applications
---

<Warning>
  This guide is a technical overview of our HIPAA compliance. Please refer to our [compliance
  page](https://compliance.elevenlabs.io/) for the latest information.
</Warning>

## Overview

ElevenLabs Conversational AI is HIPAA compliant, allowing healthcare organizations to build voice agents that handle protected health information (PHI) while maintaining regulatory compliance. This feature ensures that sensitive patient data is properly protected throughout the conversation lifecycle.

## How HIPAA compliance works

When HIPAA compliance is enabled for a workspace, the following policies are enabled:

1. **Zero Data Retention (ZDR)** - All sensitive data from conversations is automatically redacted before storage. This also applies to derivative data like LLM-produced transcript summaries, and tool call parameters and results.
2. **LLM Provider Restrictions** - Only LLMs from providers with signed Business Associate Agreements (BAAs) are available as preconfigured options
3. **Storage Limitations** - Raw audio files and transcripts containing PHI are not retained

<Note>

If you need to use LLMs that aren't pre-configured in ZDR mode (e.g., OpenAI's GPT-4o mini), you
can still do so by:

1. Obtaining a BAA directly from the provider
2. Using your API key with our Custom LLM integration

</Note>

This implementation ensures that PHI is not inadvertently stored or logged in any system components, including:

- Conversation transcripts
- Audio recordings
- Tool calls and results
- Data analytics
- System logs

<Warning>
  With Conversational AI, the BAA covers only Conversation content only - Agent configuration is
  persisted and so is not covered by Zero Retention Mode and should not include PHI. Therefore,
  documents uploaded by an agent owner to the Knowledge base aren't covered and should not include
  PHI.
</Warning>

### Enabling HIPAA compliance

<Note>
  HIPAA compliance is only available on Enterprise tier subscriptions and requires proper BAAs to be
  in place. Contact your account representative to discuss enabling this feature for your
  organization.
</Note>

## HIPAA-Compliant LLMs

When operating in HIPAA mode, only the following LLMs are available:

<AccordionGroup>
  <Accordion title="Google Models">
    - Gemini 2.0 Flash - Gemini 2.0 Flash Lite - Gemini 1.5 Flash - Gemini 1.5 Pro - Gemini 1.0 Pro
  </Accordion>
  <Accordion title="Anthropic Models">
    - Claude 3.7 Sonnet - Claude 3.5 Sonnet - Claude 3.5 Sonnet V1 - Claude 3.0 Haiku
  </Accordion>
  <Accordion title="Custom LLMs">
    - Custom LLM (always compliant as we don't process the data)
  </Accordion>
</AccordionGroup>

## Data Redaction

When HIPAA compliance is enabled, the following data is automatically redacted:

- User messages (replaced with `<REDACTED>`)
- Agent responses containing PHI
- Tool call parameters and results
- Conversation analysis and summaries
- Client-provided data via conversation initiation

## Technical Implementation

The HIPAA compliance feature implements several safeguards including but not limited to:

1. **LLM Allowlist** - Prevents use of non-compliant LLMs
2. **PII Redaction** - Automatically redacts sensitive fields before storage
3. **Storage Prevention** - Disables uploading of raw audio files to cloud

## Developer Experience

When working with HIPAA-compliant agents:

- The UI will disable non-compliant LLMs with a tooltip explanation
- API calls attempting to use non-compliant LLMs will receive an HTTP 400 error
- Conversation history will show redacted content with `<REDACTED>` placeholders
- Analytics data will be limited to non-sensitive metrics

## FAQ

<AccordionGroup>
  <Accordion title="Can I use any LLM with HIPAA compliance enabled?">
    No. When HIPAA compliance is enabled, you can only use LLMs from the approved list. Attempts to
    use non-compliant LLMs will produce an error. You can always use a custom LLM if you need a
    specific model not on the allowlist.
  </Accordion>
  <Accordion title="How do I know if my workspace has HIPAA compliance enabled?">
    HIPAA compliance is only available to enterprise customers. Please refer to your account
    executive to check if this is enabled.
  </Accordion>
  <Accordion title="Does HIPAA compliance affect conversation quality?">
    No. HIPAA compliance only affects how data is stored and which LLMs can be used. It does not
    impact the quality or functionality of conversations while they are active.
  </Accordion>
  <Accordion title="Can I still analyze conversation data with HIPAA enabled?">
    Yes, but with limitations. Conversation analytics will only include non-sensitive metadata like
    call duration and success rates. Specific content from conversations will be redacted.
  </Accordion>
</AccordionGroup>

## Best Practices

When building HIPAA-compliant voice agents:

1. **Use Custom LLMs** when possible for maximum control over data processing
2. **Implement proper authentication** for all healthcare applications
3. **Minimize PHI collection** to only what's necessary for the application
4. **Validate configuration** is correct by checking redaction before launching + passing PHI

## Related Resources

<CardGroup cols={2}>
  <Card
    title="Conversational AI Security"
    href="/docs/conversational-ai/customization/authentication"
  >
    Learn about securing your Conversational AI agents
  </Card>
  <Card title="Custom LLM Integration" href="/docs/conversational-ai/customization/custom-llm">
    Set up your own LLM for maximum control and compliance
  </Card>
</CardGroup>
